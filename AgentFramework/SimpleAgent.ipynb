{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatAgent\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from agent_framework.devui import serve\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get weather for a location.\"\"\"\n",
    "    return f\"Weather in {location}: 72°F and sunny\"\n",
    "\n",
    "# Create your agent\n",
    "agent = ChatAgent(\n",
    "    name=\"WeatherAgent\",\n",
    "    chat_client=OpenAIChatClient(),\n",
    "    tools=[get_weather]\n",
    ")\n",
    "\n",
    "# Launch debug UI - that's it!\n",
    "serve(entities=[agent], auto_open=True)\n",
    "# → Opens browser to http://localhost:8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef32d384",
   "metadata": {},
   "source": [
    "## Demo: customizing OpenAI runs\n",
    "This cell shows how to wire up `OpenAIPromptExecutionSettings` so you can fine-tune temperature, token budgets, penalties, and even force JSON output when calling Semantic Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureOpenAIChatCompletion,\n",
    "    OpenAIPromptExecutionSettings,\n",
    ")\n",
    "\n",
    "\n",
    "async def run_prompt_with_settings() -> None:\n",
    "    \"\"\"Invoke an Azure OpenAI chat deployment with explicit execution settings.\"\"\"\n",
    "    kernel = Kernel()\n",
    "\n",
    "    chat_service = AzureOpenAIChatCompletion(\n",
    "        service_id=\"gpt5-demo\",\n",
    "        api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "        endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o-mini\"),\n",
    "        api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-06-01\"),\n",
    "    )\n",
    "    kernel.add_service(chat_service)\n",
    "\n",
    "    execution_settings = OpenAIPromptExecutionSettings(\n",
    "        temperature=0.2,\n",
    "        top_p=0.9,\n",
    "        presence_penalty=0.0,\n",
    "        frequency_penalty=0.0,\n",
    "        response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"sk_summary\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"scenario\": {\"type\": \"string\"},\n",
    "                        \"impact\": {\"type\": \"string\"},\n",
    "                        \"confidence\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"minimum\": 0.0,\n",
    "                            \"maximum\": 1.0,\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"scenario\", \"impact\"],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        max_input_tokens=6000,\n",
    "        max_output_tokens=256,\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        \"Summarize one realistic Semantic Kernel use case and report its expected impact.\\n\"\n",
    "        \"Return the JSON payload requested by the schema.\"\n",
    "    )\n",
    "\n",
    "    response = await kernel.invoke_prompt(\n",
    "        prompt=prompt,\n",
    "        service_id=chat_service.service_id,\n",
    "        execution_settings=execution_settings,\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "\n",
    "\n",
    "asyncio.run(run_prompt_with_settings())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secdemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
